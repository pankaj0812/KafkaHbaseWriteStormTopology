name: "KafkaConsumer"
components:
  - id: "stringScheme"
    className: "storm.kafka.StringScheme"

  - id: "stringMultiScheme"
    className: "backtype.storm.spout.SchemeAsMultiScheme"
    constructorArgs:
      - ref: "stringScheme"

  - id: "zkHosts"
    className: "storm.kafka.ZkHosts"
    constructorArgs:
      - "${kafka.consumer.zookeeper.hosts}"

  # ProductSpout Config
  - id: "spoutConfigKafkaSpout"
    className: "storm.kafka.SpoutConfig"
    constructorArgs:
      # brokerHosts
      - ref: "zkHosts"
      # topic
      - "${spout.product.topic}"
      # zkRoot
      - ""
      # id
      - "KafkaConsumer"
    properties:
      - name: "ignoreZkOffsets"
        value: false
      - name: "scheme"
        ref: "stringMultiScheme"
      - name: "fetchSizeBytes"
        value: 8388608
config:
  topology.workers: 6
  topology.max.spout.pending: 100
  topology.acker.executors: 3
  topology.executor.send.buffer.size: 16384
  topology.executor.receive.buffer.size: 16384
#  topology.executor.receive.buffer.size: 8
  topology.transfer.buffer.size: 32
  zookeeperHost: "${appconfig.zookeeper.hosts}"
  zookeeperBasePath: "${appconfig.zookeeper.basepath}"
  kafka.broker.properties:
    metadata.broker.list: "${kafka.broker.list}"
    request.required.acks: "1"
    serializer.class: "kafka.serializer.StringEncoder"
spouts:
  - id: "CsvKafkaSpout"
    className: "storm.kafka.KafkaSpout"
    parallelism: 1
    constructorArgs:
      - ref: "spoutConfigKafkaSpout"
#  - id: "FileSpout"
#    className: "com.ugam.hbaseconsumer.topology.FileSpout"
#    parallelism: 1

bolts:
  - id: "KafkaCsvBoltv2"
    className: "main2.KafkaCsvBoltv2"
    parallelism: "${bolt.validation.parallelism}"
    constructorArgs:
      - "${hbase.metrics.table.name}"
      - "${hbase.metrics.table.cf}"


streams:

  - name: "CsvKafkaSpout --> KafkaCsvBoltv2"
    from: "CsvKafkaSpout"
    to: "KafkaCsvBoltv2"
    grouping:
      type: SHUFFLE
